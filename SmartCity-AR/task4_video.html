<!DOCTYPE html>
<html>
    <script src="https://aframe.io/releases/1.0.4/aframe.min.js"></script>
    <!-- we import arjs version without NFT but with marker
    + location based support -->
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>
    <body style="margin : 0px; overflow: hidden;">
        <a-scene embedded arjs>
			 <a-assets>
                <audio id="crazyfrogsound" src="assets/crazyfrog.mp3" response-type="arraybuffer" autoplay="true" loop></audio>
                <video id="myvideo" src="assets/crazyfrogvideo.mp4" autoplay loop="true" src="penguin-sledding.mp4"></video>
				<a-asset-item id="buggy" src="https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/KhronosGroup/glTF-Sample-Models/master/2.0/Buggy/glTF/Buggy.gltf"></a-asset-item>
            </a-assets>
			
            <!-- handle hiro marker -->
            <a-marker preset="hiro">
                <!-- raw.githack.com serves raw files directly from GitHub,
                with proper Content-Type headers -->
				<!-- first entity: reference to the above glTF model -->
                <a-entity
                position="0 -1 0"
                scale="0.004 0.004 0.004"
                gltf-model="#buggy"
                >
                </a-entity>
				
				 <!-- second entity: reference to the above audio -->
                <a-entity sound="src: #crazyfrogsound; volume: 1; loop: true">
                </a-entity>
				
            </a-marker>
			
				<!-- entity to the video -->
				<a-video src="#myvideo" width="16" height="9" position="0 0 -20"></a-video>
				
				
            <!-- add a camera to the scene that renders the objects for us -->
            <a-entity camera></a-entity>
        </a-scene>
    </body>
</html>